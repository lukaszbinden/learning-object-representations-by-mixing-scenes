\documentclass[10pt,letterpaper]{article}

\usepackage{cvpr}
\usepackage{float}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{appendix}
\pgfplotsset{compat=newest}
\usepgfplotslibrary{units}
\pgfplotsset{width=10cm,compat=1.9}
\usepgfplotslibrary{external}
\tikzexternalize
\usepackage[backend=bibtex,
style=numeric,
bibencoding=ascii
%style=alphabetic
%style=reading
]{biblatex}
\addbibresource{bibliography.bib}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}

%%%%%%%%% TITLE
\title{Learning object representations by mixing scenes}

\author{Lukas Zbinden\\
Computer Vision Group\\
Computer Science Department, University of Bern\\ 
2018\\
{\tt\small lukas.zbinden@unifr.ch}
}

\maketitle
%\thispagestyle{empty}

%=========================================================================
%%%%%%%%% ABSTRACT
\begin{abstract}
   Our project 
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
Devise a manifold learning algorithm that can discover and capture independent factors of variation.

\par Concretely, we used a ... to model the distribution over image features and the latent factors of variation.

% - from [12]
Representation learning: Supervised algorithms approach this problem by learning features which transform the data into a space where different
classes are linearly separable. However this often comes at the cost of discarding other variations such as style or pose that may be important for more general tasks. On the other hand, unsupervised learning algorithms such as autoencoders seek efficient representations of the data such that the input can be fully reconstructed, implying that the latent representation preserves all factors of variation in the data. However, without some explicit means for factoring apart the different sources of variation the factors relevant for a specific task such as categorization will be entangled with other factors across the latent variables. 

% -- from [26]
While unsupervised learning is ill-posed because the relevant downstream tasks are unknown at training time, a disentangled representation, one which explicitly represents the salient attributes of a data instance, should be helpful for the relevant but unknown tasks. For example, for a dataset of faces, a useful disentangled representation may allocate a separate set of dimensions for each of the following attributes: facial expression, eye color, hairstyle, presence or absence of eyeglasses, and the identity of the corresponding person. A disentangled representation can be useful for natural tasks that require knowledge of the salient attributes of the data, which include tasks like face recognition and object recognition.

%=========================================================================
\section{Related work}
This work builds on the results of \cite{1711.07410} and \cite{1711.02245}.
\cite{1711.02245} identifies two main challenges in disentangling factors of variation: the shortcut problem and the reference ambiguity. In the shortcut problem the model learns degenerate encodings in which all information is encoded only in one part of the feature, i.e. either in the component $c$ for common attributes shared by both images or the component $v$ for varying attributes. For an image pair there are two $v$ and one $c$. The encoder maps a complete description of its input into vector $N_v$ and the decoder completely ignores vector $N_c$.
\newline The second challenge is named reference ambiguity where the attribute representation for an image is not guaranteed to follow the same interpretation on another image. In other words, the reference in which a factor is interpreted may depend on other factors which makes the attribute transfer ambiguous. For example, the viewpoint angle of a vessel gets interpreted in two different ways depending on the boat type.
%-- [16] start -------------------------------
\par[Understanding Degeneracies and Ambiguities in Attribute Transfer] addresses these challenges. They introduce an adversarial weakly supervised training method that uses image triplets and fully tackles the shortcut problem by means of a composite loss function consisting of an autoencoder loss and an adversarial (i.e. GAN) loss. Used in conjunction they provably avoid that challenge. 
Furthermore, they analyze the reference ambiguity and prove that it is unavoidable when disentangling with only weak labels. The problem occurs when a decoder reproduces the data without satisfying the disentangling properties for the varying attribute $v$. Practically, this means not all the factors of variation can provably be disentangled from weakly labeled data (i.e. when only $c$ is known for image pairs).    
%-- [16] end -------------------------------

%-- from [12]
In previous approaches, content vs style, form vs motion, facial expression vs identity were explored.

%-- [15] start -------------------------------
\par\cite{1206.5538} elaborates on representation learning whose goal is to use unlabelled data to learn a representation that exposes important semantic features as easily decodable factors. In 3.5 they distinguish between learning invariant features and learning to disentangle explanatory factors. They conclude that the most robust approach to feature learning is to disentangle as many factors as possible, discarding as little information about the data as is practical. Doing so they propose should give rise to a good representation significantly more robust to the complex and richly structured variations extant in natural images for AI-related tasks. The manifold hypothesis is introduced which makes the assumption that the data lies along a low-dimensional manifold where the probability mass is highly concentrated. They argue that a representation being learned can be associated with an intrinsic coordinate system (on the embedded lower-dimensional manifold). For instance, this can be demonstrated well by a variational autoencoder.
%-- [15] end -------------------------------

%-- [27] start (nicht sicher ob inkludieren soll) ------------------------
[Semi-supervised learning with deep generative models] utilizes a variational autoencoder in a semi-supervised learning paradigm which is capable of separating content and style in data.
%-- [27] end -------------------------------

%-- [12] Discovering Hidden FoV in DN -- start -------------------
\par\cite{1412.6583} augments autoencoders with regularization terms during training. They use an unsupervised cross-covariance penalty (XCov) as a method to disentangle class-relevant signals (observed variables) from other factors in the latent variables along with a standard supervised cross-entropy loss. In case of MNIST they consider the class label as a high-level representation of its corresponding input. Their model learns a class invariant smooth continuous latent representation $z$ that encodes digit style (slant) whereas the observed variable $\hat{y}$ represents the digit itself. On the TFD dataset, the observed variable $\hat{y}$ encodes the facial expression while the autoencoder is able to retain the identity of the faces through latent variable $z$. Here the XCov penalty prevents expression label variation from ‘leaking’ into the latent representation.
%-- [12] end -------------------------------

%-- [20] start -------------------------------
\par\cite{1701.00160} tutors GAN in detail. 
%-- [20] end -------------------------------

%-- [24] DCGAN start -------------------------------
\par\cite{1511.06434} introduces a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate for the first time that they are a strong candidate for purely unsupervised learning. The authors propose a more stable set of architectures for training generative adversarial networks and give evidence that adversarial networks learn good representations of images. According to Ian Goodfellow, DCGAN defines a quasi-standard generator network architecture. 
%-- [24] DCGAN end -------------------------------

%-- [26] INFOGAN start -------------------------------
\par\cite{1606.03657} describes InfoGAN, a type of GAN that learns disentangled representations in an unsupervised manner (no supervision of any kind) with the addition of maximizing the mutual information between a small subset of the latent variables and the observation. InfoGAN can disentangle both discrete and continuous latent factors, scale to complicated datasets, and typically requires no more training time than regular GANs.  The effective results suggest that generative modelling augmented with a mutual information cost be a fruitful approach for learning disentangled representations. They used DCGAN for implementation and stable GAN training, respectively. Gist: concat noise vector $z$ with latent vector $c$ to form input for generator G. Additionally, extend discriminator D with Q-network on top to generate $\hat{c}$ to then calculate the reconstruction loss with $c$ and train entire network accordingly using backprob (aside the standard GAN training).
%-- [26] INFOGAN end -------------------------------

\par Many prior works on DFoV are fully supervised, i.e. they use labels for all factors of variation to be disentangled.

%=========================================================================
% Problem statement
\section{Disentangling factors of variation}
image attribute - factor of variation - feature vector - feature chunk
an object representation is learned as a concatenation of feature chunks
uses high-dimensional feature chunks
feature space is only designed for attribute transfer but not for sampling
how is disentanglement achieved? 
-> invariance objective i.e. an architecture with mixing autoencoders encourages disentangled encoding of attributes and disentangled decoding of feature chunks, respectively
-> classification objective such that each feature chunk corresponds to a discernible attribute in the original image 
encoding of an attribute, decoding of a feature chunk

\par\cite{1412.6583} states in 2014 that there is a lack of standard benchmark tasks for evaluating disentangling performance. Their evaluation is based on examining qualitatively what factors of variation are discovered for different datasets. ALS INSPIRATION: In [12]: "To visualize the transformations that the latent variables are learning, the decoder can be used to create images for different values of z. We vary a single element zi linearly over a set interval with zni fixed to 0 and y fixed to one-hot vectors corresponding to each class label. Moving across each column for a given row, the digit style is maintained as the class labels varies. This suggests the network has learned a class invariant latent representation". Auch für meinen Autoencoder machen um Beispiele aufzuzeigen?

\par "A disentangled representation is generally described as one which separates the factors of variation, explicitly representing the important attributes of the data" [a framework for the quantitative evaluation of disentangled representations]

\par image space vs feature space paper [42]

%=========================================================================
% Method
\section{Learning object representations by mixing scenes}
image attribute - factor of variation - feature vector - feature chunk
an object representation is learned as a concatenation of feature chunks

\par LEARN A MODEL THAT IDENTIFIES OBJECTS IN THE SCENE AND LEARNS TO COMPOSE THEM SO YOU CAN MERGE SCENES.

\par https://arxiv.org/pdf/1803.06414.pdf "Learning to Segment via Cut-and-Paste": We propose and formalize a new cut-and-paste adversarial training scheme for box-supervised instance segmentation, which captures an intuitive prior, that objects can move independently of their background.
-> perhaps use latter sentence as idea for the intuition that we're trying to "move objects around independently of their background"

\par what is the theoretical groundwork for the proposed method?

\par We use a GAN to check for realism of the generated images.

\par This subsection explicates the reason ...

\par A baseline could also be pure chance s.a. 50 percent chance..

\par an encoder for computing a low-dimensional latent representation, and a decoder for synthesizing the output image.

how do I enforce invariance between object representations and object attribute representations, respectively?
x3 should be a valid image according to the input data distribution.

The classifier consists of $3x3x8$ multi-class classifiers, one for each chunk, that decide for each chunk the original image ($x_1$, $x_2$) and the specific tile, respectively, that was used to generate a tile of the composite image.

(Hinweis: [12] has nice formulation of cost function, perhaps use as inspiration)

\par To generate the unbalanced mask $m$ with a bias towards the first of the two contexts, we used a Bernoulli distribution with $p=0.6$ and $q=1-p=0.4$, respectively, such that $Pr(X=1)=0.6$ and $Pr(X=0)=1-P(X=1)=0.4$ where $1$ represents the first context (i.e. image $x_1$) and $0$ the second context (i.e. image $x_2$).

\par During training of modified DCGAN encountered lack of GAN training, i.e. the generator loss was immediately 0, the discriminator loss 27.6 ($dsc_loss_real$ was 0 and $dsc_loss_fake$ was 27.6 (meaning the discriminator always output 1 no matter the input). To counteract this problem we implemented and used spectral normalization for GANs (also SNGAN, \cite{1802.05957}) to regularize the Lipschitz constant. With the latter in place, the GAN training set in.

\par In high dimensional spaces, embeddings?

\par Some methods are based on new mathematical models and others based on intuition back up by experiments.

\par In \cite{1611.03383} Vielleicht als Inspiration für 'Qualitativ evaluation': "we performed nearest neighbor retrieval in the learned embedding spaces... We computed the corresponding representations for all samples (for the unspecified component we used the mean of the approximate posterior distribution) and then retrieved the nearest neighbors for a given query image"

\subsection{Architecture}
Training Procedure: Our models are implemented in TensorFlow \cite{1605.08695} and are trained using a batch size of 4 instances for the generator and 8 instances for the...
Cf. paper https://arxiv.org/pdf/1803.06414.pdf

%=========================================================================
\section{Experimental Results}
We first evaluate the performance of our learned representations on different
transfer learning benchmarks. We then perform ablation studies on our proposed
method. We also visualize the neurons of the intermediate layers of our network.
We experimentally show...

\subsection{Datasets}
\subsubsection{Places}
A 10 million Image Database for Scene Recognition. The Places dataset contains significantly more complex factors of variation than MNIST.

\subsubsection{Microsoft COCO}
On average the Microsoft COCO dataset \cite{1405.0312} contains 3.5 categories and 7.7 instances per image. Another interesting observation is only 10\% of the images in MS COCO have only one category per image.
validation set: total: 5000, greaterThan300: 4916, moreThan4: 2430
training set: total: 118287, greaterThan300: 116510, moreThan4: 57180
For data augmentation we use random crops four times per image, resulting in a dataset size of 228720.

\subsection{Training}
We train the model to maximize the data log-likelihood using SGD.
Training strategies for disentangling:...
The training with ... did not yield well-disentangled features as the generated images were blurry and not representing objects and sceneries well. 


\subsection{Model Performance}
We evaluated the model using the MS Coco dataset first.
We hypothesize...
We find empirically that...
Thus, both quantitative and qualitative results demonstrate...
We found that the model is not sensitive to this hyperparameter
The model achieves strong performance in ...

\par Paper https://arxiv.org/pdf/1806.05575.pdf says "The evaluation metric used for the hyperparameter search was the Frechet Inception Distance (FID)"

\subsection{Qualitative and quantitative evaluation}
See paper [a framework for the quantitative evaluation of disentangled representations]: "visual inspection remains the standard evaluation
metric"; "current research generally lacks a clear metric for quantitatively evaluating and comparing disentangled representations."
Evtl. "Disentanglement metric score" verwenden aus Paper 41 für Comparison mit anderen Models?

%=========================================================================
\section{Conclusion}
None of our image preprocessing attempts
We show ...

\section{Future work}
In general, run the experiments

\printbibliography

%=========================================================================
\begin{appendices}
\section{Appendix}
The contents...
\end{appendices}


\end{document}
