\documentclass[10pt,letterpaper]{article}

\usepackage{cvpr}
\usepackage{float}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{appendix}
\pgfplotsset{compat=newest}
\usepgfplotslibrary{units}
\pgfplotsset{width=10cm,compat=1.9}
\usepgfplotslibrary{external}
\tikzexternalize
\usepackage[backend=bibtex,
style=numeric,
bibencoding=ascii
%style=alphabetic
%style=reading
]{biblatex}
\addbibresource{bibliography.bib}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}

%%%%%%%%% TITLE
\title{Learning object representations by mixing scenes}

\author{Lukas Zbinden\\
Computer Vision Group\\
Computer Science Department, University of Bern\\ 
2018\\
{\tt\small lukas.zbinden@unifr.ch}
}

\maketitle
%\thispagestyle{empty}

%-------------------------------------------------------------------------
%%%%%%%%% ABSTRACT
\begin{abstract}
   Our project 
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
In 2017 the Radiological Society of North America (RSNA) published.

%-------------------------------------------------------------------------
\section{Related work}
This work builds on the results of \cite{1711.07410} and \cite{1711.02245}.
[2] identifies two main challenges in disentangling factors of variation: the shortcut problem and the reference ambiguity. In the shortcut problem the model learns degenerate encodings in which all information is encoded only in one part of the feature, i.e. either in the component $c$ for common attributes shared by both images or the component $v$ for varying attributes. For an image pair there are two $v$ and one $c$. The encoder maps a complete description of its input into vector $N_v$ and the decoder completely ignores vector $N_c$.
\newline The second challenge is named reference ambiguity where the attribute representation for an image is not guaranteed to follow the same interpretation on another image. In other words, the reference in which a factor is interpreted may depend on other factors which makes the attribute transfer ambiguous. For example, the viewpoint angle of a vessel gets interpreted in two different ways depending on the boat type.
%-- [16] start -------------------------------
\par[Understanding Degeneracies and Ambiguities in Attribute Transfer] addresses these challenges. They introduce an adversarial weakly supervised training method that uses image triplets and fully tackles the shortcut problem by means of a composite loss function consisting of an autoencoder loss and an adversarial (i.e. GAN) loss. Used in conjunction they provably avoid that challenge. 
Furthermore, they analyze the reference ambiguity and prove that it is unavoidable when disentangling with only weak labels. The problem occurs when a decoder reproduces the data without satisfying the disentangling properties for the varying attribute $v$. Practically, this means not all the factors of variation can provably be disentangled from weakly labeled data (i.e. when only $c$ is known for image pairs).    
%-- [16] end -------------------------------
%-- [15] start -------------------------------
\par\cite{1206.5538} elaborates on representation learning. In 3.5 they distinguish between learning invariant features and learning to disentangle explanatory factors. They conclude that the most robust approach to feature learning is to disentangle as many factors as possible, discarding as little information about the data as is practical. Doing so they propose should give rise to a good representation significantly more robust to the complex and richly structured variations extant in natural images for AI-related tasks.


%-- [15] end -------------------------------
\par Many prior works on DFoV are fully supervised, i.e. they use labels for all factors of variation to be disentangled.

%------------------------------------------------------------------------
% Problem statement
\section{Disentangling factors of variation}
We proposed 

%-------------------------------------------------------------------------
% Method
\section{Learning object representations by mixing scenes}
We evaluated the

%-------------------------------------------------------------------------
\section{Results}
We evaluated the
We hypothesize

%------------------------------------------------------------------------
\section{Conclusion}
None of our image preprocessing attempts

\section{Future work}
In general, run the experiments

\printbibliography

%------------------------------------------------------------------------
\begin{appendices}
\section{Appendix}
The contents...
\end{appendices}


\end{document}
